{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning and gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is continuation of the notebook MLPclassifierwithdropout.ipynb. In this notebook, we will use gridsearch to tune the hyperparameters for our regularization techniques. By hyperparameter, I mean the following:\n",
    "- The stopping time for training.\n",
    "- The dropout rate `dr` when implementing dropout.\n",
    "- The learning rate `lr` used in training our models.\n",
    "- The momentum parameter `m` used by the optimizer.\n",
    "- The weight decay parameter `wd` in the L2 regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    log_loss,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_predict,\n",
    "    StratifiedKFold,\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, LabelEncoder\n",
    ")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchaudio\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import itertools as it\n",
    "\n",
    "def to_prob(metric):\n",
    "    @functools.wraps(metric)\n",
    "    def metric_that_takes_prob(y_actual, y_pred, sample_weight=None):\n",
    "        return metric(y_actual, y_pred.argmax(1), sample_weight=sample_weight)\n",
    "\n",
    "    return metric_that_takes_prob\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    \"accuracy\": to_prob(accuracy_score),\n",
    "    \"balanced_accuracy\": to_prob(balanced_accuracy_score),\n",
    "    \"unweighted_f1\": to_prob(functools.partial(f1_score, average=\"macro\")),\n",
    "    \"UAR\": to_prob(functools.partial(recall_score, average=\"macro\")),\n",
    "    \"logloss\": log_loss,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.featureDataSets import *\n",
    "from scripts.utility_functions import *\n",
    "from scripts.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, since we want to carry out early stopping, we want to measure cross-validation in a manner akin to the `cross_validate` function imported from `scripts.utility_functions`. This means our current way of training and seeing results over CV are incompatible with the usual libraries. While it may be possible to use `skorch` to make it all work, it's easier for me to just write a naive gridsearch by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a useful function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range(hps, hp):\n",
    "    log_range=np.linspace(np.log10(hps[hp][0]), np.log10(hps[hp][1]) , hps[hp][2], dtype=float) #range cannot include 0.\n",
    "    return 10**log_range\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our implementation of gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twolayergridsearch(hps, df=P05_t):\n",
    "# hps should be a dictionary with hps.keys() equal to ['dr', 'lr', 'm', 'wd'] and with each key a 3-tuple (start,stop, num) describing the range to be searched, and the number of pts to check in that range.\n",
    "    ranges_list=[range(hps, hp) for hp in hps.keys()]\n",
    "    grid=list(it.product(*ranges_list))\n",
    "    selector=pd.DataFrame()\n",
    "    selector.index.name=\"('dr','lr','m','wd')\"\n",
    "    selector[\"best_f1_val\"]=[0]*len(grid)\n",
    "    selector[\"f1_val_stop\"]=[0]*len(grid)\n",
    "    selector[\"best_logloss_val\"]=[0]*len(grid)\n",
    "    selector[\"logloss_val_stop\"]=[0]*len(grid)\n",
    "    for i, pt in enumerate(tqdm(grid)):\n",
    "        model_pt=two_layer_classifier_do(num_labels=len(P05_t.Label.unique()), dr=pt[0])\n",
    "        output_pt = crossvalid_nobar(model=model_pt, df=df, k_fold=3, lr=pt[1], m=pt[2], wd=pt[3])\n",
    "        df_f1=output_pt['unweighted_f1']\n",
    "        df_logloss=output_pt['logloss']\n",
    "        selector.loc[i, 'best_f1_val']=(df_f1['split_0_val']+df_f1['split_1_val']+df_f1['split_2_val']).max()/3\n",
    "        selector.loc[i, 'f1_val_stop']=(df_f1['split_0_val']+df_f1['split_1_val']+df_f1['split_2_val']).argmax()\n",
    "        selector.loc[i, 'best_logloss_val']=(df_logloss['split_0_val']+df_logloss['split_1_val']+df_logloss['split_2_val']).min()/3\n",
    "        selector.loc[i, 'logloss_val_stop']=(df_logloss['split_0_val']+df_logloss['split_1_val']+df_logloss['split_2_val']).argmin()\n",
    "    selector.index=grid\n",
    "    return selector\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f996d382d7d5430da6957cc2fd51cb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/180 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m hps\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdr\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m1e-1\u001b[39m,\u001b[38;5;241m5e-1\u001b[39m,\u001b[38;5;241m5\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-2\u001b[39m, \u001b[38;5;241m6\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m8e-1\u001b[39m,\u001b[38;5;241m9e-1\u001b[39m,\u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwd\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m1e-5\u001b[39m,\u001b[38;5;241m1e-3\u001b[39m,\u001b[38;5;241m3\u001b[39m)}\n\u001b[0;32m----> 2\u001b[0m selector\u001b[38;5;241m=\u001b[39m\u001b[43mtwolayergridsearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m selector\n",
      "Cell \u001b[0;32mIn[25], line 13\u001b[0m, in \u001b[0;36mtwolayergridsearch\u001b[0;34m(hps, df)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(grid)):\n\u001b[1;32m     12\u001b[0m     model_pt\u001b[38;5;241m=\u001b[39mtwo_layer_classifier_do(num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(P05_t\u001b[38;5;241m.\u001b[39mLabel\u001b[38;5;241m.\u001b[39munique()), dr\u001b[38;5;241m=\u001b[39mpt[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m     output_pt \u001b[38;5;241m=\u001b[39m \u001b[43mcrossvalid_nobar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_pt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     df_f1\u001b[38;5;241m=\u001b[39moutput_pt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munweighted_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m     df_logloss\u001b[38;5;241m=\u001b[39moutput_pt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/github_rahul/erdos_dl_recanvo_project/rk/scripts/utility_functions.py:188\u001b[0m, in \u001b[0;36mcrossvalid_nobar\u001b[0;34m(model, loss, df, k_fold, batch_size, n_epochs, lr, m, wd, random_state)\u001b[0m\n\u001b[1;32m    186\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    187\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m--> 188\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m X_train, y_train, z_train\u001b[38;5;241m=\u001b[39mget_all(train_set)\n\u001b[1;32m    190\u001b[0m X_val, y_val, z_val\u001b[38;5;241m=\u001b[39mget_all(val_set)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fastbook/lib/python3.12/site-packages/torch/optim/optimizer.py:469\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    468\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 469\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    470\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# call optimizer step pre hooks\u001b[39;49;00m\n\u001b[1;32m    471\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_global_optimizer_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step_pre_hooks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpre_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fastbook/lib/python3.12/site-packages/torch/autograd/profiler.py:688\u001b[0m, in \u001b[0;36mrecord_function.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprofiler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_record_function_enter_new\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fastbook/lib/python3.12/site-packages/torch/_ops.py:1061\u001b[0m, in \u001b[0;36mOpOverloadPacket.__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m self_\u001b[38;5;241m.\u001b[39m_has_torchbind_op_overload \u001b[38;5;129;01mand\u001b[39;00m _must_dispatch_in_python(args, kwargs):\n\u001b[1;32m   1060\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _call_overload_packet_from_python(self_, args, kwargs)\n\u001b[0;32m-> 1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mself_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hps={'dr': (1e-1,5e-1,5), 'lr': (1e-5, 1e-2, 6), 'm': (8e-1,9e-1,2), 'wd':(1e-5,1e-3,3)}\n",
    "selector=twolayergridsearch(hps)\n",
    "selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector['best_f1_val'].nlargest(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.001, 0.9, 0.001)                                      0.856862\n",
       "(0.08891397050194613, 0.00015848931924611142, 0.9, 0.001)     0.877056\n",
       "(0.2811706625951745, 0.001, 0.8, 0.001)                       0.881455\n",
       "(0.5, 0.001, 0.8, 0.001)                                      0.884058\n",
       "(0.049999999999999996, 0.00015848931924611142, 0.9, 0.001)    0.884820\n",
       "Name: best_f1_val, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selector['best_logloss_val'].nsmallest(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can repeat the same thing for three layer networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threelayergridsearch(hps, df=P05_t):\n",
    "# hps should be a dictionary with hps.keys() equal to ['dr', 'lr', 'm', 'wd'] and with each key a 3-tuple (start,stop, num) describing the range to be searched, and the number of pts to check in that range.\n",
    "    ranges_list=[range(hps, hp) for hp in hps.keys()]\n",
    "    grid=list(it.product(*ranges_list))\n",
    "    selector=pd.DataFrame()\n",
    "    selector.index.name=\"('dr','lr','m','wd')\"\n",
    "    selector[\"best_f1_val\"]=[0]*len(grid)\n",
    "    selector[\"f1_val_stop\"]=[0]*len(grid)\n",
    "    selector[\"best_logloss_val\"]=[0]*len(grid)\n",
    "    selector[\"logloss_val_stop\"]=[0]*len(grid)\n",
    "    for i, pt in enumerate(tqdm(grid)):\n",
    "        model_pt=three_layer_classifier_do(num_labels=len(P05_t.Label.unique()), dr=pt[0])\n",
    "        output_pt = crossvalid_nobar(model=model_pt, df=df, k_fold=3, lr=pt[1], m=pt[2], wd=pt[3])\n",
    "        df_f1=output_pt['unweighted_f1']\n",
    "        df_logloss=output_pt['logloss']\n",
    "        selector.loc[i, 'best_f1_val']=(df_f1['split_0_val']+df_f1['split_1_val']+df_f1['split_2_val']).max()/3\n",
    "        selector.loc[i, 'f1_val_stop']=(df_f1['split_0_val']+df_f1['split_1_val']+df_f1['split_2_val']).argmax()\n",
    "        selector.loc[i, 'best_logloss_val']=(df_logloss['split_0_val']+df_logloss['split_1_val']+df_logloss['split_2_val']).min()/3\n",
    "        selector.loc[i, 'logloss_val_stop']=(df_logloss['split_0_val']+df_logloss['split_1_val']+df_logloss['split_2_val']).argmin()\n",
    "    selector.index=grid\n",
    "    return selector\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc5bf8cf32a146469e95df1599082221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/120 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m hps3\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdr\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m5e-2\u001b[39m,\u001b[38;5;241m5e-1\u001b[39m,\u001b[38;5;241m5\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m1e-3\u001b[39m, \u001b[38;5;241m6\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;241m8e-1\u001b[39m,\u001b[38;5;241m9e-1\u001b[39m,\u001b[38;5;241m2\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwd\u001b[39m\u001b[38;5;124m'\u001b[39m:(\u001b[38;5;241m1e-3\u001b[39m,\u001b[38;5;241m1e-1\u001b[39m,\u001b[38;5;241m2\u001b[39m)}\n\u001b[0;32m----> 2\u001b[0m selector3\u001b[38;5;241m=\u001b[39m\u001b[43mtwolayergridsearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhps3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m selector3\n",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m, in \u001b[0;36mtwolayergridsearch\u001b[0;34m(hps, df)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(grid)):\n\u001b[1;32m     12\u001b[0m     model_pt\u001b[38;5;241m=\u001b[39mtwo_layer_classifier_do(num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(P05_t\u001b[38;5;241m.\u001b[39mLabel\u001b[38;5;241m.\u001b[39munique()), dr\u001b[38;5;241m=\u001b[39mpt[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m     output_pt \u001b[38;5;241m=\u001b[39m \u001b[43mcrossvalid_nobar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_pt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_fold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     df_f1\u001b[38;5;241m=\u001b[39moutput_pt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munweighted_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m     df_logloss\u001b[38;5;241m=\u001b[39moutput_pt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/workspace/github_rahul/erdos_dl_recanvo_project/rk/scripts/utility_functions.py:189\u001b[0m, in \u001b[0;36mcrossvalid_nobar\u001b[0;34m(model, loss, df, k_fold, batch_size, n_epochs, lr, m, wd, random_state)\u001b[0m\n\u001b[1;32m    187\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    188\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m--> 189\u001b[0m X_train, y_train, z_train\u001b[38;5;241m=\u001b[39m\u001b[43mget_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m X_val, y_val, z_val\u001b[38;5;241m=\u001b[39mget_all(val_set)\n\u001b[1;32m    192\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m#put in evaluation mode to determine predicted values on train and validation sets\u001b[39;00m\n",
      "File \u001b[0;32m~/workspace/github_rahul/erdos_dl_recanvo_project/rk/scripts/utility_functions.py:72\u001b[0m, in \u001b[0;36mget_all\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m     70\u001b[0m z\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[0;32m---> 72\u001b[0m     X[i], y[i], z[i] \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, y, z\n",
      "File \u001b[0;32m/opt/anaconda3/envs/fastbook/lib/python3.12/site-packages/torch/utils/data/dataset.py:412\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[0;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/workspace/github_rahul/erdos_dl_recanvo_project/rk/scripts/featureDataSets.py:96\u001b[0m, in \u001b[0;36mPrecomputedFeatures.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     94\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mFilename\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m     95\u001b[0m X\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/HuBERt_features/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mfilename\u001b[38;5;241m.\u001b[39mremovesuffix(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m---> 96\u001b[0m y\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabeldict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m y[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabeldict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mLabel\u001b[38;5;241m.\u001b[39miloc[idx]]]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     98\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabeldict[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mLabel\u001b[38;5;241m.\u001b[39miloc[idx]]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hps3={'dr': (1e-1,5e-1,5), 'lr': (1e-5, 1e-2, 6), 'm': (9e-1,10e-1,1), 'wd':(1e-5,1e-3,3)} #momentum has been having little effect in earlier runs of this cell, so I fixed it at m=.9.\n",
    "selector3=twolayergridsearch(hps3)\n",
    "selector3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With AdamW as the optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also check to see what this tuning spits out when we run with AdamW as the optimizer. Note that `optim.AdamW` does not take a parameter `m` for momentum. Instead, it uses `betas` which is a $2$-tuple used for computing running averages of the gradient and its square. We won't gridsearch in these dimensions - AdamW takes long enough as is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our input dictionaries are a little shorter, since there is no momementum to care about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twolayergridsearch_AdamW(hps, df=P05_t):\n",
    "# hps should be a dictionary with hps.keys() equal to ['dr', 'lr', 'wd'] and with each key a 3-tuple (start,stop, num) describing the range to be searched, and the number of pts to check in that range.\n",
    "    ranges_list=[range(hps, hp) for hp in hps.keys()]\n",
    "    grid=list(it.product(*ranges_list))\n",
    "    selector=pd.DataFrame()\n",
    "    selector.index.name=\"('dr','lr','wd')\"\n",
    "    selector[\"best_f1_val\"]=[0]*len(grid)\n",
    "    selector[\"f1_val_stop\"]=[0]*len(grid)\n",
    "    selector[\"best_logloss_val\"]=[0]*len(grid)\n",
    "    selector[\"logloss_val_stop\"]=[0]*len(grid)\n",
    "    for i, pt in enumerate(tqdm(grid)):\n",
    "        model_pt=two_layer_classifier_do(num_labels=len(P05_t.Label.unique()), dr=pt[0])\n",
    "        output_pt = crossvalid_AdamW_nobar(model=model_pt, df=df, k_fold=3, lr=pt[1], wd=pt[2])\n",
    "        df_f1=output_pt['unweighted_f1']\n",
    "        df_logloss=output_pt['logloss']\n",
    "        selector.loc[i, 'best_f1_val']=(df_f1['split_0_val']+df_f1['split_1_val']+df_f1['split_2_val']).max()/3\n",
    "        selector.loc[i, 'f1_val_stop']=(df_f1['split_0_val']+df_f1['split_1_val']+df_f1['split_2_val']).argmax()\n",
    "        selector.loc[i, 'best_f1_val']=(df_logloss['split_0_val']+df_logloss['split_1_val']+df_logloss['split_2_val']).min()/3\n",
    "        selector.loc[i, 'f1_val_stop']=(df_logloss['split_0_val']+df_logloss['split_1_val']+df_logloss['split_2_val']).argmin()\n",
    "    selector.index=grid\n",
    "    return selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps2_AdamW={'dr': (5e-2,5e-1,5), 'lr': (1e-5, 1e-3, 6), 'wd':(1e-3,1e-1,2)}\n",
    "selector2A=twolayergridsearch_AdamW(hps2_AdamW)\n",
    "selector2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threelayergridsearch_AdamW(hps, df=P05_t):\n",
    "# hps should be a dictionary with hps.keys() equal to ['dr', 'lr', 'wd'] and with each key a 3-tuple (start,stop, num) describing the range to be searched, and the number of pts to check in that range.\n",
    "    ranges_list=[range(hps, hp) for hp in hps.keys()]\n",
    "    grid=list(it.product(*ranges_list))\n",
    "    selector=pd.DataFrame()\n",
    "    selector.index.name=\"('dr','lr','wd')\"\n",
    "    selector[\"best_f1_val\"]=[0]*len(grid)\n",
    "    selector[\"f1_val_stop\"]=[0]*len(grid)\n",
    "    selector[\"best_logloss_val\"]=[0]*len(grid)\n",
    "    selector[\"logloss_val_stop\"]=[0]*len(grid)\n",
    "    for i, pt in enumerate(tqdm(grid)):\n",
    "        model_pt=three_layer_classifier_do(num_labels=len(P05_t.Label.unique()), dr=pt[0])\n",
    "        output_pt = crossvalid_AdamW_nobar(model=model_pt, df=df, k_fold=3, lr=pt[1], wd=pt[2])\n",
    "        df_f1=output_pt['unweighted_f1']\n",
    "        df_logloss=output_pt['logloss']\n",
    "        selector.loc[i, 'best_f1_val']=(df_f1['split_0_val']+df_f1['split_1_val']+df_f1['split_2_val']).max()/3\n",
    "        selector.loc[i, 'f1_val_stop']=(df_f1['split_0_val']+df_f1['split_1_val']+df_f1['split_2_val']).argmax()\n",
    "        selector.loc[i, 'best_f1_val']=(df_logloss['split_0_val']+df_logloss['split_1_val']+df_logloss['split_2_val']).min()/3\n",
    "        selector.loc[i, 'f1_val_stop']=(df_logloss['split_0_val']+df_logloss['split_1_val']+df_logloss['split_2_val']).argmin()\n",
    "    selector.index=grid\n",
    "    return selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hps3_AdamW={'dr': (5e-2,5e-1,5), 'lr': (1e-5, 1e-3, 6), 'wd':(1e-3,1e-1,2)}\n",
    "selector3A=twolayergridsearch_AdamW(hps3_AdamW)\n",
    "selector3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
